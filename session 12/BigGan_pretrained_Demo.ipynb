{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-DkYe3L-z_R"
      },
      "source": [
        "#BigGan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1igTQdn-zU5"
      },
      "source": [
        "!pip install pytorch-pretrained-biggan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_7_8B7G-xdb",
        "outputId": "8ba7959a-d2cb-4754-ceb4-a6cc08fb18e8"
      },
      "source": [
        "import nltk\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import logging\r\n",
        "nltk.download('wordnet')\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import torch\r\n",
        "from pytorch_pretrained_biggan import *\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "device = 'cuda'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpHEpD2rDkhQ"
      },
      "source": [
        "def vector_linspace(start, end, steps):\r\n",
        "  \"\"\"\r\n",
        "  Vector version of torch linspace\r\n",
        "  \"\"\"\r\n",
        "  result = []\r\n",
        "  for dim in range(start.shape[0]):\r\n",
        "    result.append(torch.linspace(start[dim], end[dim], steps))\r\n",
        "  result = torch.stack(result, dim=1).to(device)\r\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ7NFMYTDRqF"
      },
      "source": [
        "def show_noise_interpolations(n_rows, n_cols, image_size,truncation, label, scale=3):\r\n",
        "    \"\"\"\r\n",
        "    Shows image interpolation (grid of [`n_rows`, `n_cols`]) in input noise space.\r\n",
        "    \"\"\"\r\n",
        "    N = n_rows * n_cols\r\n",
        "    class_vector = one_hot_from_names([label] * N, batch_size=N)\r\n",
        "    anchor_noises = truncated_noise_sample(truncation=truncation, batch_size=4)\r\n",
        "\r\n",
        "    anchor_noises = torch.from_numpy(anchor_noises).to(device)\r\n",
        "    class_vector = torch.from_numpy(class_vector).to(device)\r\n",
        "\r\n",
        "    left_column = vector_linspace(anchor_noises[0], anchor_noises[1], n_rows)\r\n",
        "    right_column = vector_linspace(anchor_noises[2], anchor_noises[3], n_rows)\r\n",
        "    rows = []\r\n",
        "    for i in range(n_rows):\r\n",
        "      rows.append(vector_linspace(left_column[i], right_column[i], n_cols))\r\n",
        "    noises = torch.stack(rows, dim=0).view(n_rows * n_cols, -1)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      fake_imgs = model(noises, class_vector, truncation)\r\n",
        "\r\n",
        "    biggan_grid_show(fake_imgs,image_size, n_rows, scale=scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3B5D5gAAGc9"
      },
      "source": [
        "def biggan_grid_show(image_batch, image_size, rows=1, scale=3):\r\n",
        "  \"\"\"\r\n",
        "  This function gets multiple images and plots them in the given number of rows.\r\n",
        "  \"\"\"\r\n",
        "  image_batch = image_batch.detach().cpu()\r\n",
        "  image_batch = image_batch.view(-1, 3, image_size, image_size)\r\n",
        "  image_batch = image_batch.numpy()\r\n",
        "\r\n",
        "  cols = np.ceil(image_batch.shape[0] / rows)\r\n",
        "  plt.rcParams['figure.figsize'] = (cols * scale, rows * scale)\r\n",
        "\r\n",
        "  for i in range(image_batch.shape[0]):\r\n",
        "    img = convert_to_images(np.expand_dims(image_batch[i], axis=0))[0]\r\n",
        "    plt.subplot(rows, cols, i + 1)\r\n",
        "    # plt.imshow(np.transpose(img, [1, 2, 0]))\r\n",
        "    plt.imshow(img)\r\n",
        "    plt.axis('off')\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGNAOo67D9Zq"
      },
      "source": [
        "def show_class_interpolations(n_rows, n_cols, image_size, truncation, labels, scale=3):\r\n",
        "    \"\"\"\r\n",
        "    Shows image interpolation (grid of [`n_rows`, `n_cols`]) in input noise space.\r\n",
        "    \"\"\"\r\n",
        "    assert len(labels) == 4\r\n",
        "    N = n_rows * n_cols\r\n",
        "    class_vector = one_hot_from_names(labels, batch_size=4)\r\n",
        "    noise = truncated_noise_sample(truncation=truncation, batch_size=1)\r\n",
        "\r\n",
        "    noise = torch.from_numpy(noise).to(device)\r\n",
        "    class_vector_anchors = torch.from_numpy(class_vector).to(device)\r\n",
        "\r\n",
        "    left_column = vector_linspace(class_vector_anchors[0], class_vector_anchors[1], n_rows)\r\n",
        "    right_column = vector_linspace(class_vector_anchors[2], class_vector_anchors[3], n_rows)\r\n",
        "    rows = []\r\n",
        "    for i in range(n_rows):\r\n",
        "      rows.append(vector_linspace(left_column[i], right_column[i], n_cols))\r\n",
        "    \r\n",
        "    class_vectors = torch.stack(rows, dim=0).view(n_rows * n_cols, -1)\r\n",
        "    noises = noise.expand(n_rows * n_cols, -1)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      fake_imgs = model(noises, class_vectors, truncation)\r\n",
        "\r\n",
        "    biggan_grid_show(fake_imgs,image_size, n_rows, scale=scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5HJW3KO_9VD"
      },
      "source": [
        "import torch\r\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\r\n",
        "                                       save_as_images, display_in_terminal)\r\n",
        "\r\n",
        "import logging\r\n",
        "logging.basicConfig(level=logging.INFO)\r\n",
        "\r\n",
        "model = BigGAN.from_pretrained('biggan-deep-256') #128 , 256, 512.\r\n",
        "\r\n",
        "truncation = 0.5\r\n",
        "class_vector = one_hot_from_names(['soap bubble', 'coffee', 'mushroom'], batch_size=3)\r\n",
        "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=3)\r\n",
        "\r\n",
        "noise_vector = torch.from_numpy(noise_vector)\r\n",
        "class_vector = torch.from_numpy(class_vector)\r\n",
        "\r\n",
        "noise_vector = noise_vector.to('cuda')\r\n",
        "class_vector = class_vector.to('cuda')\r\n",
        "model.to('cuda')\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    output = model(noise_vector, class_vector, truncation)\r\n",
        "    output = output.to('cpu')\r\n",
        "\r\n",
        "biggan_grid_show(output,image_size=256, rows=1, scale=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN6PJl64_vFX"
      },
      "source": [
        "truncation = 0.5\r\n",
        "batch_size = 4\r\n",
        "\r\n",
        "#use labels like : ladybug , cheetah , ...\r\n",
        "class_vector = one_hot_from_names(['mushroom', 'husky', 'coffee' , 'ladybug'], batch_size=batch_size)\r\n",
        "\r\n",
        "#use class numbers : 0 to 999\r\n",
        "# class_vector = one_hot_from_int([548, 234, 300, 800], batch_size=batch_size)\r\n",
        "\r\n",
        "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=batch_size)\r\n",
        "\r\n",
        "noise_vector = torch.from_numpy(noise_vector).to(device)\r\n",
        "class_vector = torch.from_numpy(class_vector).to(device)\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "  output = model(noise_vector, class_vector, truncation)\r\n",
        "  output = output.cpu()\r\n",
        "\r\n",
        "biggan_grid_show(output,image_size = 256, rows=1, scale=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAT-I1vTAhFr"
      },
      "source": [
        "show_noise_interpolations(4, 4,256, truncation=0.5, label='husky', scale=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVdBGfYgDg09"
      },
      "source": [
        "show_class_interpolations(4, 4,256 , truncation=.4, labels=['dog', 'husky', 'tiger', 'cheetah'], scale=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWO5o1qYnOJw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}